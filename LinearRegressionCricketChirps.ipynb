{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXPDDjvZA0yp"
   },
   "source": [
    "# Example Linear Regression\n",
    "\n",
    "This notebook contains a walkthrough of a simple linear regression. The data, obtained from [college.cengage.com](http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/frame.html), relates the rate of cricket chirps to temperature from *The Song of Insects*, by Dr. G. W. Pierce, Harvard College Press.\n",
    "\n",
    "In this example we're using the count of chirps per minute as the independent varible to then predict the dependent variable, temperature. In short, we're using a little data science to make ourselves a cricket thermometer. (You could also reverse the data and use temperature to predict the number of chirps, but it's more fun to use crickets as the thermometer itself!) \n",
    "\n",
    "The methods shown in this example follow what's presented in the Udemy course, [Machine Learning A to Z](https://www.udemy.com/machinelearning/learn/v4/).\n",
    "\n",
    "A lovely aspects of Notebooks is that you can use Markdown cells to explain what the code is doing rather than code comments. There are several benefits to doing so:\n",
    "\n",
    "- Markdown allows for richer text formatting, like *italics*, **bold**, `inline code`, hyperlinks, and headers.\n",
    "- Markdown cells automatically word wrap whereas code cells do not. Code comments typically use explicit line breaks for formatting, but that's not necessary in Markdown.\n",
    "- Using Markdown cells makes it easier to run the Notebook as a slide show.\n",
    "- Markdown cells help you remove lengthy comments from the code, making the code easier to scan.\n",
    "\n",
    "When you run a code cell, Jupyter executes the code; when you run a Markdown cell, Jupyter renders all the formatting into text that's suitable for presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LUcPPV-zA0yq"
   },
   "source": [
    "## Install packages using pip or conda\n",
    "\n",
    "Because the code in your notebook likely uses some Python packages, you need to make sure the Notebook environment contains those packages. You can do this directly within the notebook in a code block that contains the appropriate pip or conda commands prefixed by `!`:\n",
    "\n",
    "```\n",
    "!pip install <pkg name> \n",
    "\n",
    "!conda install <pkg name> -y\n",
    "```\n",
    "\n",
    "This present notebook requires numpy, matplotlib, pandas, and sklearn. Because these packages are already included in Azure Notebooks, the following commands are commented out but are included to clearly note the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdS-Mt9ZA0ys"
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install pandas\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3wlXypqA0yw"
   },
   "source": [
    "Note that when you run a code block that contains install commands, and also those with `import` statements, it make take the notebook a little time to complete the task. To the left of the code block you see `In [*]` to indicate that execution is happening. The Notebook's kernel on the upper right also shows a filled-in circle to indicate \"busy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Wm99QZCA0yx"
   },
   "source": [
    "## Import libraries and prepare the dataset\n",
    "\n",
    "In this example we're using numpy, pandas, and matplotlib. Data is in the file cricket_chirps.csv. The cell below loads the file directly from the GitHub repository. If using colab, you should generally access data files remotely. On your own computer, the data file should be in the same project as this present Notebook, we can just load it using a relative pathname, e.g. `pd.read_csv('cricket_chirps.csv')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1568016071200,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "duH8bHlSA0yy",
    "outputId": "c30d9f4d-8bd0-4a71-a60c-903d38320540"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('https://raw.githubusercontent.com/kuo-courses/hw00-f19/master/cricket_chirps.csv')\n",
    "print(dataset)\n",
    "X = dataset.iloc[:, :-1].values  # Matrix of independent variables -- remove the last column in this data set\n",
    "y = dataset.iloc[:, 1].values    # Matrix of dependent variables -- just the last column (1 == 2nd column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EsTiWN6VA0y1"
   },
   "source": [
    "Next, split the dataset into a Training set (2/3rds) and Test set (1/3rd). We don't need to do any feature scaling because there is only one column of independent variables, and libraries typically do scaling for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRl6dhqGA0y1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsawQAt_A0y3"
   },
   "source": [
    "## Fit the data to the training set\n",
    "\n",
    "\"Fitting\" the data to a training set means making the line that describes the relationship between the independent and the dependent variables. With a simple data set like we're using here, you can visualize the line on a simple x-y plot: the x-axis is the independent variable (chirp count in this example), and the y-axis is the independent variable (temperature). Fitting the data means plotting all the points in the training set, then drawing the best-fit line through that data.\n",
    "\n",
    "With two independent variables you can imagine a three-dimensional plot with a line fitted to the data. At three or more independent variables, however, it's no longer easy to visualize the fit, but you get the idea. In the end, it's all just mathematics, which a computer can handle easily without having to form a mental picture!\n",
    "\n",
    "The regressor's `fit` method here creates the line, which algebraically is of the form `y = x*b1 + b0`, where b1 is the coefficient or slope of the line (which you can get to through `regressor.coef_`), and b0 is the intercept of the line at x=0 (which you can get to through `regressor.intercept`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1568016071947,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "4Jt9mfaNA0y4",
    "outputId": "d14e3cb1-01b9-48bf-a74c-d83b1f01d86c"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()    # This object is the regressor, that does the regression\n",
    "regressor.fit(X_train, y_train)   # Provide training data so the machine can learn to predict using a learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8A8dLjQLA0y6"
   },
   "source": [
    "## Predict the results\n",
    "\n",
    "With the regressor in hand, we can predict the test set results using its `predict` method. That method takes a vector of independent variables for which you want predictions.\n",
    "\n",
    "Because the regressor is fit to the data by virtue of `coef_` and `intercept_` and `coef_`, a prediction is the result of `coef_ * x + intercept_`. (Indeed, `predict(0)` returns `intercept_` and `predict(1)` returns `intercept_ + coef_`.)\n",
    "\n",
    "In the code, the `y_test` matrix (from when we split the set) contains the real observations. `y_pred` assigned here contains the predictions for the same `X_test` inputs. It's not expected that the test or training points exactly fit the regression; the regression is trying to find the model that we can use to make predictions with new observations of the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1568016071948,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "1YUbmtpsA0y6",
    "outputId": "79404f9c-4f00-4b25-9e64-e35de688bd3c"
   },
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZQXMv5IA0y7"
   },
   "source": [
    "It's interesting to think that all the \"predictions\" we use in daily life, like weather forecasts, are just regression models of some sort working with various data sets. Those models are much more complicated than what's shown here, but the idea is the same.\n",
    "\n",
    "Knowing how predictions work help us understand that the actual observations we would collect in the moment will always be somewhat off from the predictions: the predictions fit exactly to the model, whereas the observations typically won't.\n",
    "\n",
    "Of course, such systems feed new observations back into the dataset to continually improve the model, meaning that predictions should get more accurate over time.\n",
    "\n",
    "The challenge is determining what data to actually use. For example, with weather, how far back in time do you go? How have weather patterns been changing decade by decade? In any case, something like weather predictions will be doing things hour by hour, day by day, for things like temperature, precipitation, winds, cloud cover, etc. Radar and other observations are of course fed into the model and the predictions are reduced to mathematics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tl7_2KHDA0y8"
   },
   "source": [
    "## Visualize the results\n",
    "\n",
    "The following code generates a plot: green dots are training data, red dots are test data, blue dots are predictions. Gray line is the regression itself. You see that all the blue dots are exactly on the line, as they should be, because the predictions exactly fit the model (the line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1568016072098,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 360
    },
    "id": "D1mEOvuzA0y8",
    "outputId": "08e2eb9e-cb4d-4d3f-e899-9f71b56e5e8e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_train, y_train, color = 'green')\n",
    "plt.scatter(X_test, y_test, color = 'red')   \n",
    "plt.scatter(X_test, y_pred, color = 'blue')  # The predicted temperatures of the same X_test input.\n",
    "plt.plot(X_train, regressor.predict(X_train), color = 'gray')\n",
    "plt.title('Temperature based on chirp count')\n",
    "plt.xlabel('Chirps/minute')\n",
    "plt.ylabel('Temperature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iq1L13HrA0y9"
   },
   "source": [
    "## Closing comments\n",
    "\n",
    "At the end of the day, when you create a model, you use training data. Then you start feeding test data (real observations) to see how well the model actually works. You may find that the model is a little inaccurate over time, in which case you retrain the model with some new data. Retraining the model means you're creating a new fit line that's used for predictions.\n",
    "\n",
    "This regression can be used to examine the variability of the relationship between temperature and chirp count. Of course, if the model proves too inaccurate (that is, the predictions aren't very good), then it suggests that we might need to introduce more independent variables like humidity, time of year, latitude, amount of moonlight, and so on. If you have such data, you can do separate lines regressions for each independent variable, and then do multiple regressions with combinations of independent variables. \n",
    "\n",
    "Again, once you are working with more than one or two independent variables, it's much easier to use machine learning to crunch the numbers than to try to visualize it graphically."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of LinearRegressionCricketChirps.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/kuo-courses/hw00-f19/blob/master/LinearRegressionCricketChirps.ipynb",
     "timestamp": 1568016165872
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
